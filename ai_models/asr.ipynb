{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-26T09:09:52.187411Z",
     "iopub.status.busy": "2025-03-26T09:09:52.187144Z",
     "iopub.status.idle": "2025-03-26T09:10:00.633415Z",
     "shell.execute_reply": "2025-03-26T09:10:00.632272Z",
     "shell.execute_reply.started": "2025-03-26T09:09:52.187390Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (1.3)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Collecting sox\n",
      "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (75.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2.4.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\n",
      "Building wheels for collected packages: wget, sox\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=2c4c8691bef6c3016e2e7d6449c63396162bc52dd8f892f4b4d0e62c93009654\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40037 sha256=141bd70928b9aa4972106a5d8dc9fce2ca7f3a782074a3cfd2280318a1304565\n",
      "  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n",
      "Successfully built wget sox\n",
      "Installing collected packages: wget, sox\n",
      "Successfully installed sox-1.5.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchaudio librosa wget text-unidecode omegaconf sox pydub ipython soundfile funasr nemo_toolkit[asr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:14:54.898269Z",
     "iopub.status.busy": "2025-03-26T09:14:54.897951Z",
     "iopub.status.idle": "2025-03-26T09:15:14.292200Z",
     "shell.execute_reply": "2025-03-26T09:15:14.291299Z",
     "shell.execute_reply.started": "2025-03-26T09:14:54.898242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nemo.collections.asr.models import EncDecMultiTaskModel\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import display, Audio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pydub.utils import mediainfo\n",
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'running on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TranscriptionModel:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.BATCH_SIZE = 30\n",
    "        self.FRAME_RATE = 16000\n",
    "        self.kwargs=kwargs\n",
    "        self.model_name = kwargs[\"model_name\"]\n",
    "        self.device = kwargs.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.build_model(**kwargs)\n",
    "\n",
    "    \n",
    "    def get_length(self, input_file):\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        length = len(audio) / 1000\n",
    "        return length\n",
    "\n",
    "    def convert(self, input_file, output_file, format):\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        audio.export(output_file, format=format)\n",
    "\n",
    "    \n",
    "    def convertTo16kHzMono(self, input_file):\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(input_file, format=\"wav\")\n",
    "\n",
    "    \n",
    "    def build_model(self, **configs):\n",
    "        model_name = configs.pop(\"model_name\")\n",
    "        if model_name == \"canary_1b_flash\":\n",
    "            self.model = EncDecMultiTaskModel.from_pretrained(model_name=\"nvidia/canary-1b-flash\", \n",
    "                                                                map_location=self.device)\n",
    "            \n",
    "        elif model_name == \"sense_voice_small\":\n",
    "            SenseVoiceSmall_dir = \"FunAudioLLM/SenseVoiceSmall\"\n",
    "            vad_model = configs.get(\"vad_model\", \"fsmn-vad\")\n",
    "            vad_kwargs = configs.get(\"vad_kwargs\", {\"max_single_segment_time\": 30000})\n",
    "            device = configs.get(\"device\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            hub = configs.get(\"hub\", \"hf\")\n",
    "            \n",
    "            self.model = AutoModel(\n",
    "                model=SenseVoiceSmall_dir,\n",
    "                vad_model=vad_model,\n",
    "                vad_kwargs=vad_kwargs,\n",
    "                device=device,\n",
    "                hub=hub,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model name. Please use either 'canary_1b_flash' or'sense_voice_small'.\")\n",
    "\n",
    "    \n",
    "##################################################################################################################################################\n",
    "    def transcribe_audio(self, **kwargs):\n",
    "        try:\n",
    "            self.input_file = kwargs.get(\"input_file\")\n",
    "            if self.input_file is None:\n",
    "                raise ValueError(\"input_file couldn't be found!\")\n",
    "            \n",
    "            if not os.path.exists(self.input_file):\n",
    "                raise FileNotFoundError(f\"The file {self.input_file} does not exist.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return {}, {}\n",
    "    \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return {}, {}\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return {}, {}\n",
    "            \n",
    "        self.use_overlay = kwargs.get(\"use_overlay\", False)\n",
    "        self.batch_size = kwargs.get(\"batch_size\", self.BATCH_SIZE)\n",
    "        self.start_time = kwargs.get(\"start_time\", 0)\n",
    "        self.end_time = min(kwargs.get(\"end_time\", self.get_length(self.input_file)), self.get_length(self.input_file))\n",
    "\n",
    "\n",
    "        if self.model_name == \"canary_1b_flash\":\n",
    "            self.source_lang = kwargs.get(\"source_lang\", \"en\")\n",
    "            self.target_lang = kwargs.get(\"target_lang\", \"en\")\n",
    "            self.pnc = kwargs.get(\"pnc\", \"yes\")\n",
    "            #self.timestamps = kwargs.get(\"timestamps\", \"yes\")\n",
    "    \n",
    "        elif self.model_name == \"sense_voice_small\":\n",
    "            self.language = kwargs.get(\"language\", \"auto\")\n",
    "            self.use_itn = kwargs.get(\"use_itn\", True)\n",
    "            self.batch_size_s = kwargs.get(\"batch_size_s\", self.batch_size)\n",
    "            self.merge_vad = kwargs.get(\"merge_vad\", True)\n",
    "            self.merge_length_s = kwargs.get(\"merge_length_s\", self.batch_size//2)\n",
    "    \n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model name. Please use either 'canary_1b_flash' or'sense_voice_small'.\")\n",
    "    \n",
    "    \n",
    "        transcriptions, transcriptions_obj = self.transcribe_audio_segments(**kwargs)\n",
    "    \n",
    "        return transcriptions, transcriptions_obj\n",
    "    \n",
    "    \n",
    "##################################################################################################################################################\n",
    "    def transcribe_audio_segments(self, **kwargs):\n",
    "        if not self.input_file.endswith('.wav'):\n",
    "            temp_filename = f\"temp_file.wav\"\n",
    "            self.convert(self.input_file, temp_filename, 'wav')\n",
    "            self.input_file = temp_filename\n",
    "\n",
    "        audio = AudioSegment.from_file(self.input_file)\n",
    "        \n",
    "        if audio.channels!= 1 or audio.frame_rate!= self.FRAME_RATE:\n",
    "            self.convertTo16kHzMono(self.input_file)\n",
    "\n",
    "        audio = AudioSegment.from_file(self.input_file)\n",
    "        audio_duration = len(audio) // 1000\n",
    "\n",
    "        start_time_ms = int(self.start_time * 1000)\n",
    "        end_time_ms = int(self.end_time * 1000)\n",
    "        trimmed_audio = audio[start_time_ms:end_time_ms]\n",
    "\n",
    "        batch_num = int((end_time_ms - start_time_ms) // (self.batch_size * 1000)) + ((end_time_ms - start_time_ms) % (self.batch_size * 1000) > 0)\n",
    "\n",
    "        transcriptions = {}\n",
    "        transcriptions_obj = {}\n",
    "\n",
    "        for i in tqdm(range(batch_num), desc=\"Transcribing segments\"):\n",
    "            start_time = i * self.batch_size * 1000\n",
    "            end_time = min(start_time + self.batch_size * 1000, end_time_ms)\n",
    "\n",
    "            \n",
    "            if end_time - start_time < self.batch_size * 1000 & self.use_overlay:\n",
    "                start_time = end_time - self.batch_size * 1000\n",
    "\n",
    "            audio_segment = trimmed_audio[start_time : end_time]\n",
    "\n",
    "            temp_filename = f\"temp_segment_{i}.wav\"\n",
    "            audio_segment.export(temp_filename, format=\"wav\")\n",
    "\n",
    "\n",
    "            \n",
    "            if self.model_name == \"canary_1b_flash\":\n",
    "                transcription = self.model.transcribe(\n",
    "                    audio=[temp_filename],\n",
    "                    source_lang=self.source_lang,\n",
    "                    target_lang=self.target_lang,\n",
    "                    pnc=str(self.pnc),\n",
    "                    #timestamps=self.timestamps NotImplementedError: Computing timestamps are not supported for this model yet.\n",
    "                )\n",
    "                time_interval = f\"[{(start_time + start_time_ms) // 1000}:{(end_time + start_time_ms) // 1000}]\"\n",
    "                #transcriptions[time_interval] = rich_transcription_postprocess(transcription[0].text)\n",
    "                '''rich_transcription_postprocess is a funasr function'''\n",
    "                transcriptions[time_interval] = transcription[0].text\n",
    "                transcriptions_obj[time_interval] = transcription\n",
    "\n",
    "            \n",
    "            elif self.model_name == \"sense_voice_small\":\n",
    "                transcription = self.model.generate(\n",
    "                    input=temp_filename,\n",
    "                    cache={},\n",
    "                    language=self.language,\n",
    "                    use_itn=self.use_itn,\n",
    "                    batch_size_s=self.batch_size_s,\n",
    "                    merge_vad=self.merge_vad,\n",
    "                    merge_length_s=self.merge_length_s,\n",
    "                )\n",
    "\n",
    "                time_interval = f\"[{(start_time + start_time_ms) // 1000}:{(end_time + start_time_ms) // 1000}]\"\n",
    "                transcriptions[time_interval] = rich_transcription_postprocess(transcription[0][\"text\"])\n",
    "                transcriptions_obj[time_interval] = transcription\n",
    "            \n",
    "            os.remove(temp_filename)\n",
    "\n",
    "        return transcriptions, transcriptions_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-26T11:37:13.925009Z",
     "iopub.status.busy": "2025-03-26T11:37:13.924661Z",
     "iopub.status.idle": "2025-03-26T11:37:33.471280Z",
     "shell.execute_reply": "2025-03-26T11:37:33.470177Z",
     "shell.execute_reply.started": "2025-03-26T11:37:13.924979Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714902acc9a04b039c82a9e48c7b45d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 29 files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect model requirements, begin to install it: C:\\Users\\baybe\\.cache\\huggingface\\hub\\models--FunAudioLLM--SenseVoiceSmall\\snapshots\\3eb3b4eeffc2f2dde6051b853983753db33e35c3\\requirements.txt\n",
      "fail to install model requirements! \n",
      "error   error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [19 lines of output]\n",
      "      + C:\\Users\\baybe\\anaconda3\\envs\\deb\\python.exe C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\\vendored-meson\\meson\\meson.py setup C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5 C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\\.mesonpy-mcgzeifm -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\\.mesonpy-mcgzeifm\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\n",
      "      Build dir: C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\\.mesonpy-mcgzeifm\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      C compiler for the host machine: gcc (gcc 6.3.0 \"gcc (MinGW.org GCC-6.3.0-1) 6.3.0\")\n",
      "      C linker for the host machine: gcc ld.bfd 2.28\n",
      "      C++ compiler for the host machine: c++ (gcc 6.3.0 \"c++ (MinGW.org GCC-6.3.0-1) 6.3.0\")\n",
      "      C++ linker for the host machine: c++ ld.bfd 2.28\n",
      "      Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "      Host machine cpu family: x86\n",
      "      Host machine cpu: x86\n",
      "      \n",
      "      ..\\meson.build:28:4: ERROR: Problem encountered: NumPy requires GCC >= 8.4\n",
      "      \n",
      "      A full log can be found at C:\\Users\\baybe\\AppData\\Local\\Temp\\pip-install-7hq6tk3n\\numpy_231f901a3d40445894f99130f4640cd5\\.mesonpy-mcgzeifm\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Ã— Encountered error while generating package metadata.\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\baybe\\.cache\\modelscope\\hub\\models\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:47:13,444 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "rtf_avg: 0.007: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00,  4.45it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.005: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 3/3 [00:00<00:00, 20.32it/s]\n",
      "rtf_avg: 0.005, time_speech:  30.000, time_escape: 0.154: 100%|\u001b[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00,  6.27it/s]\n",
      "rtf_avg: 0.003: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00, 11.14it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.006: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 3/3 [00:00<00:00, 17.16it/s]\n",
      "rtf_avg: 0.006, time_speech:  30.000, time_escape: 0.181: 100%|\u001b[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00,  5.36it/s]\n",
      "rtf_avg: 0.004: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00, 13.06it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "rtf_avg: 0.006: 100%|\u001b[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 2/2 [00:00<00:00, 15.36it/s]\n",
      "rtf_avg: 0.007, time_speech:  20.000, time_escape: 0.136: 100%|\u001b[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1/1 [00:00<00:00,  7.10it/s]\n",
      "Transcribing segments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "transcription_model = TranscriptionModel(\n",
    "    model_name=\"sense_voice_small\", #  \"sense_voice_small\", \"canary_1b_flash\"\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "transcriptions_text, transcriptions_obj = transcription_model.transcribe_audio(\n",
    "    input_file = \"audio_files\\en\\min2_speech.mp3\",\n",
    "    end_time = 80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0:30]': \"Thank you all for not sleeping in. After I heard all about all the great fun last night, I figured that, you know, Lauren and I would be the only ones here. So thank you for, for joining us.What my hope is. And I'm very pleased to be with all of you and M E I today. My hope is that I can.ðŸ˜ŠIn our short time today, get you to think a little differently, especially about consumers, especially about my world, which is the supermarket and.\",\n",
       " '[30:60]': \"Especially about trends. So what I want to do is get started by showing you an actual advertisement from about 100 years ago. It's a picture of the hog with a child's head on the body.Says makes children and adults as fat as pigs, no cure, No pay price 50 cents Groroves tasteless chillilnic on the market over 20 years,50 cents,100 years ago. We're talking about a very expensive product here.Anybody want to take a guess what's in.\",\n",
       " '[60:80]': 'That bottle, just yell it out. water, sugar water, whiskey. We know what you were doing last night. Any other guesses.Cocaine, fat. It was.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0:30]': [{'key': 'temp_segment_0',\n",
       "   'text': \"<|en|><|HAPPY|><|Speech|><|withitn|>Thank you all for not sleeping in. After I heard all about all the great fun last night, I figured that, you know, Lauren and I would be the only ones here. So thank you for, for joining us. <|en|><|HAPPY|><|Speech|><|withitn|>What my hope is. And I'm very pleased to be with all of you and M E I today. My hope is that I can. <|en|><|NEUTRAL|><|Speech|><|withitn|>In our short time today, get you to think a little differently, especially about consumers, especially about my world, which is the supermarket and.\"}],\n",
       " '[30:60]': [{'key': 'temp_segment_1',\n",
       "   'text': \"<|en|><|NEUTRAL|><|Speech|><|withitn|>Especially about trends. So what I want to do is get started by showing you an actual advertisement from about 100 years ago. It's a picture of the hog with a child's head on the body. <|en|><|EMO_UNKNOWN|><|Speech|><|withitn|>Says makes children and adults as fat as pigs, no cure, No pay price 50 cents Groroves tasteless chillilnic on the market over 20 years,50 cents,100 years ago. We're talking about a very expensive product here. <|en|><|EMO_UNKNOWN|><|Speech|><|withitn|>Anybody want to take a guess what's in.\"}],\n",
       " '[50:80]': [{'key': 'temp_segment_2',\n",
       "   'text': \"<|en|><|EMO_UNKNOWN|><|Speech|><|withitn|>Sense Groroves tasteless chill tonic on the market over 20 years,50 cents100 years ago. We're talking about a very expensive product here. Any want to take a guess what's in that bottle. Just yell it out, water. <|en|><|EMO_UNKNOWN|><|Laughter|><|withitn|>Sugar water, whiskey. We know what you were doing last night. Any other guesses, cocaine, fat. <|en|><|EMO_UNKNOWN|><|Speech|><|withitn|>It was.\"}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_obj"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6970618,
     "sourceId": 11169785,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "deb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
